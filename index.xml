<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>SeeYu</title><link>https://www.notes.wang/</link><description>Recent content on SeeYu</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Wed, 19 Feb 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://www.notes.wang/index.xml" rel="self" type="application/rss+xml"/><item><title>AI发展史</title><link>https://www.notes.wang/post/ai%E5%8F%91%E5%B1%95%E5%8F%B2/</link><pubDate>Wed, 19 Feb 2025 00:00:00 +0000</pubDate><guid>https://www.notes.wang/post/ai%E5%8F%91%E5%B1%95%E5%8F%B2/</guid><description>
人工智能发展史：从图灵测试到GPT时代的历程 当你在深夜与ChatGPT畅聊人生，当Midjourney为你画出想象中的奇幻场景，当Sora生成逼真的视频片段——你是否想过，这一切是如何开始的？
人工智能（AI）的发展史，是一部人类探索智能奥秘、挑战自我极限的壮丽史诗。今天，让我们穿越时光，回顾这段充满激情、挫折与奇迹的旅程。
萌芽期：梦想的种子（1950年代之前） “机器能思考吗？”
1936年，天才数学家艾伦·图灵提出了“图灵机”的概念，为计算机科学奠定了基础。1950年，他发表了划时代的论文《计算机器与智能》，开篇就提出了这个问题，并设计了著名的“图灵测试”——如果一台机器能在对话中让人无法分辨它是人还是机器，就说明它具有智能。
与此同时，神经科学家也在探索大脑的工作原理。1943年，麦卡洛克和皮茨提出了第一个神经元的数学模型，为神经网络埋下了种子。
诞生：达特茅斯会议的夏天（1956年） 1956年夏天，美国达特茅斯学院的一场会议，正式宣告了人工智能的诞生。
约翰·麦卡锡（他创造了“Artificial Intelligence”这个词）、马文·明斯基、克劳德·香农等十位科学家聚在一起，畅想：“如果能精确描述学习或智能的每一个方面，就能制造一台机器来模拟它。”
这个夏天点燃了第一波AI热潮。早期成果令人振奋：
1951年，第一个神经网络SNARC问世 1956年，逻辑理论家程序证明了数学定理 1957年，弗兰克·罗森布拉特发明了感知机 寒冬与复苏：期望与现实的落差（1970s-1980s） 第一次AI寒冬（1974-1980）
早期的乐观很快被现实浇醒。当时的计算机算力不足，感知机甚至无法解决简单的异或问题。1969年，明斯基和帕佩特出版《感知机》一书，指出了神经网络的局限性。加上英国莱特希尔报告对AI的严厉批评，英美政府大幅削减经费，AI进入第一个寒冬。
专家系统时代（1980s）
1980年代，一种新思路带来转机——专家系统。通过将人类专家的知识编码成规则，程序可以在特定领域（如医疗诊断、地质勘探）提供专业建议。
日本1981年启动第五代计算机项目，欧美也纷纷跟进。但专家系统难以获取知识、难以应对复杂现实，维护成本高昂。1980年代末，随着日本项目失败，AI迎来第二个寒冬。
第三次浪潮：机器学习的崛起（1990s-2010） 这一次，AI不再试图模仿人类推理，而是转向数据驱动的方法。
关键突破：
1989年，杨立昆（Yann LeCun）提出卷积神经网络，用于手写数字识别 1997年，IBM的深蓝击败国际象棋冠军卡斯帕罗夫 支持向量机、随机森林等算法成熟 统计革命：AI从逻辑推理转向概率统计，从“告诉我规则”变成“从数据中学习”。
深度学习革命（2012-2018） 2012年，ImageNet图像识别大赛上，辛顿团队用深度神经网络AlexNet将错误率从25%降至15%，震惊学界。
这背后是三大要素的完美结合：
大数据：互联网带来了海量数据 强算力：GPU让大规模并行计算成为可能 新算法：ReLU激活函数、Dropout等技术 此后，AI迎来爆发：
2016年，AlphaGo击败李世石 2017年，Transformer架构论文《Attention Is All You Need》发表 计算机视觉、语音识别达到人类水平 大语言模型时代（2018-至今） Transformer架构开启了大语言模型时代：
2018年：GPT-1发布，参数量1.17亿 2019年：GPT-2（15亿参数），因“太危险”暂不开放 2020年：GPT-3（1750亿参数），展现惊人能力 2022年：ChatGPT发布，5天用户破百万 2023-2024年：GPT-4、Claude、Gemini、Sora等涌现 我们正处在AI发展最快的历史时期。
结语：历史的启示 回顾AI发展史，可以总结出几个规律：
周期律：狂热 → 失望 → 寒冬 → 新突破 → 再狂热 技术融合：每次突破都源于算力、数据、算法的协同进化 基础研究的重要性：Transformer架构源于2017年的论文 面对AI的未来，保持理性乐观最为重要。1956年达特茅斯会议上的先驱们，如果看到今天的AI，一定会感到欣慰。而今天的我们，正站在一个新的历史起点上。
未来，更加深入的AI探索，以及将AI运用到各个行业，势必会多点开花。</description></item><item><title>软件工程师使用ChatGPT日常——高效理解技术细节</title><link>https://www.notes.wang/post/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B%E5%B8%88%E4%BD%BF%E7%94%A8chatgpt%E6%97%A5%E5%B8%B8%E9%AB%98%E6%95%88%E7%90%86%E8%A7%A3%E6%8A%80%E6%9C%AF%E7%BB%86%E8%8A%82/</link><pubDate>Fri, 07 Apr 2023 00:00:00 +0000</pubDate><guid>https://www.notes.wang/post/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B%E5%B8%88%E4%BD%BF%E7%94%A8chatgpt%E6%97%A5%E5%B8%B8%E9%AB%98%E6%95%88%E7%90%86%E8%A7%A3%E6%8A%80%E6%9C%AF%E7%BB%86%E8%8A%82/</guid><description>
问题 最近在整理一些关于Helm在大型企业中实践的内容，突然想到一个关于Helm的最佳实践：
Chart names must be lower case letters and numbers. Words may be separated with dashes(-)
在各种软件产品中，我不止一次看到对于大小写，破折号/下划线的要求。这次看到Helm的最佳实践，我依然很疑惑——为什么不使用大写字符和破折号会成为一个最佳实践？如果说为了命名风格一致，但为什么甚至会在某些软件中被直接禁止？比如Helm在install时如果存在大写或者下划线会直接报错。
关于这个问题我尝试使用传统的搜索引擎，但并不能很好的找到答案： 通过ChatGPT来搜索答案 从上图可以看到，搜出来的结果基本都是重复官方要求的不能使用下划线和大写字母。如果利用ChatGPT来找答案，是否能得到一个更好的答案呢？ 以下是我的对话记录： 从回答中可以看出是因为Kubernetes的命名规范限制了作为工具的Helm的命名，这很好理解。但是Kubernetes为什么会要求命名不能使用大写呢？继续追问： 经过两轮对话，ChatGPT已经给出了关键原因：为了避免操作系统中对于大小写不一致的处理方式可能会导致无法正确识别和处理对象。当然这也不够直接，继续问一个更具体的案例： 到这里，答案基本就明了：在Linux中能够创建myFile.txt和MyFile.txt的两个文件，但是如果同样的创建方式在Windows中执行一遍，就会出错。因此就有了通过规定只允许小写字母来避免这样的问题发声。
总结 整个过程，只用了大概2分钟，如果使用传统的搜索引擎，我并没有办法很快找到答案。ChatGPT在解决这个问题上有很大优势。 但ChatGPT在处理这样的日常任务时就完全没有缺点吗？当然不是。有以下这几个问题：
提问（Prompt）的方式决定回答的质量
相比于传统的搜索引擎靠关键字的方式，ChatGPT的问题方式事实上变得复杂了很多，同时也变得尤为关键。你描述的详细程度，描述的方式发生变化，得到的答案也不一样。同一个问题，我换一种问法，如下图所示： 这是一个相对直接的提问方式，得到的答案就和之前大不相同了。这里的解释是需要保持和Kubernetes命名规范一致，并没有像前文一样解释命名不一致可能会导致无法在部署时被Kubernetes正确解析和部署。
回答的准确性
有时候ChatGPT的答案并不准确，相比之下，有一个靠谱的网站背书+一定数量的评论，这样的答案可信度更高。而ChatGPT的回答，比如： 我们是否敢直接用来做一些重要结论的依据呢？
准确的回答就一定好？
我并不觉得准确的回答就一定好。很多时候我们使用搜索引擎去尝试解决一个问题，不只是为了解决问题本身，也希望能够从解决问题的过程中学到一些相关的知识，但是直接了当的回答，是否会一定程度的限制我们想象力的衍生呢？
当然总的来说，将ChatGPT当作一个高级的搜索引擎来解决一些具体问题，的确是能够提高效率的，可以一试。</description></item><item><title>学软件技术一定要实战？</title><link>https://www.notes.wang/post/%E5%AD%A6%E8%BD%AF%E4%BB%B6%E4%B8%80%E5%AE%9A%E8%A6%81%E5%AE%9E%E6%88%98/</link><pubDate>Sun, 19 Mar 2023 00:00:00 +0000</pubDate><guid>https://www.notes.wang/post/%E5%AD%A6%E8%BD%AF%E4%BB%B6%E4%B8%80%E5%AE%9A%E8%A6%81%E5%AE%9E%E6%88%98/</guid><description>
学习软件技术要实战，可能是多数从业者的共识。但为什么学习软件技术要实战？实战无论是寻找合适的实战项目还是进行实战需要的时间都要比阅读一本技术书籍或者技术博客的投入要高得多的多得多&amp;hellip;所以如果不实战，就没有办法学好软件？不得不说，进行实战时，虽然会投入更多的时间和精力，但也确实能将知识掌握的更牢靠，或者说知识留存率更高，这大概也是 学习软件技术要实战的共识由来。但这也并不意味着学习软件技术一定要实战。
实战能更好地掌握软件技术的原因在于，实战能给你提供更多的上下文，而不只是你想要学的。在实战中，你以为你只学到了一个知识点，实际上你学到了可能十几个甚至更多的知识点。而且这些知识点都围绕着同一个场景展开，可以更容易地被吸收进你自身的知识体系，从而就更容易被运用。最终就让人觉得实战能够将知识掌握得更牢靠，换句话说就是会用了。而你通过读书学来的东西，则直截了当得多，往往就只有那一个知识点，针对性很强。这些点状得知识，并没有那么容易和你自己得知识体系融合，进而被你运用。
之所以要实战，关键在于实战可以给你：
学到更多相关联的知识，形成知识网络，而不仅是知识点； 知识对应的应用场景信息，包括问题的发生原因、解决经过、解决结果。 那如果在阅读技术书籍和博客的过程中就能做到这两点，那是不是就能达到接近实战的学习效果呢？我认为答案是肯定的。
首先关于第一个关键点：学习知识网络，而非知识点。举个简单的例子，在学习一门新的程序语言的时候，与之前学习的程序语言做对比。根据对之前程序语言的学习经验，抽象一些需要掌握的模块，比如设计思想，亮点，基本语法，提供的方法库，著名的项目等。通过读书来了解这门新语言后，知识或多或少就和已经掌握的语言建立了一个连接，这可以帮助我们更快速高效地掌握了这门新语言。
当然这还不够，这样的连接还是相对较弱，所以关注第二个关键点，帮助我们促进新知识和已有知识网络的融合。可以在读书的过程中，不断地思考，向自己发问，诸如“这个程序语言用来开发这样的项目为什么会更合适？”，“为什么这门程序语言会更适合高并发？”等等。这些问题都是这门语言的应用场景，在不断地弄清楚这些问题的过程中，实际上也就是在不断地学习具体应用场景，进而不断地加强新知识与已有知识的连接。
实战并非学习技术的唯一途径，但实战绝对是软件从业者最重要的学习手段之一。只是在我们无法获得这些实战机会的时候，记得学习软件技术并非一定要实战。</description></item><item><title>签名你的Git提交</title><link>https://www.notes.wang/post/%E7%AD%BE%E5%90%8D%E4%BD%A0%E7%9A%84git%E6%8F%90%E4%BA%A4/</link><pubDate>Sat, 19 Feb 2022 00:00:00 +0000</pubDate><guid>https://www.notes.wang/post/%E7%AD%BE%E5%90%8D%E4%BD%A0%E7%9A%84git%E6%8F%90%E4%BA%A4/</guid><description>
目录 什么是签名Git的提交？ Git提交为什么需要签名？ 如何签名？ 原理解析 引用 什么是签名Git的提交？ 1. 什么是签名Git的提交？ 下图是一张被签名过后的提交(Commit)，在Github上的展示：
与普通Commit的区别在于其多了一个 Verified标识。这个标识能够被所有有权查看Commit的人看到，从而让大家更加信任这个Commit确实是作者本人提交的。而签名Git的提交正是显示 Verified标识的最核心的一步。
2. Git提交为什么需要签名？ 简单来说就是避免自己或者他人的Commit被伪造。
如今Git已然成为源码管理领域的重要成员，无数程序员使用Git作为其源码管理工具。那些以Git为核心的各种商业软件，如Github，Gitlab，Bitbucket等，每天接收大量的Git Commits。毫无疑问，这些Commit就是企业最重要的财产。即便如此，对于Commit本身的安全性，却没有得到太多的重视。当然Commit本身只是Git软件下的一个重要概念，保护Git软件的安全一定程度也能够保障Commit的安全，但这绝不是一个好的将Commit的安全放任不管的理由。要知道如果你什么都不做，Repository中的Commit是可以轻易被伪造的。而签名Git的提交正是为了解决这个问题而来。
3. 如何签名？ 签名本身是一个简单的动作，尤其是在Git 2.34版本后，支持了SSH签名，对于那些本就使用SSH验证身份的用户就更加容易了。Github也支持使用GPG或者S/MIME进行签名，不过GPG相比于SSH更加复杂，S/MIME则主要用于企业。这里的例子以相对简单的Github上的SSH签名来演示。
生成密钥对 使用以下命令生成Key-Pair[1]
$ ssh-keygen -t ed25519 -C &amp;quot;your_email@example.com&amp;quot;
建议使用ed25519，相比于rsa 4096bit更快的速度，同时安全性也没有损失太多。
配置Github 打开“setting”页面的“SSH and GPG keys”：
将上一步生成的公钥xxx.pub中的内容作为Signing Key上传到Github： 签名部分的配置就完成了，为了在Github上显示 Verified标识，还需要打开“SSH and GPG keys”页面里的“Vigilant mode”[2]： 配置git&amp;lt;sup&amp;gt;[3]&amp;lt;/sup&amp;gt; 配置Git使用SSH来签名Commit
$ git config --global gpg.format ssh
配置Git使用指定路径的公钥作为SSH的Signing Key
$ git config --global user.signingkey ~/.ssh/ed25519.pub
配置IDE（IntelliJ为例） 在commit页面上，点击设置，并勾选“Sign-off commit”，如下图所示： 签名并提交 $ git commit -S -m &amp;quot;this is a signed commit&amp;quot;</description></item></channel></rss>